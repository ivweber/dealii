<h1>Results</h1>

When running the program, you get output that looks like this:
@code
Mesh refinement step 0
  Target_tolerance: 0.001

  Computing residual vector... norm=0.867975
  Computing Jacobian matrix
  Factorizing Jacobian matrix
  Solving linear system
  Computing residual vector... norm=0.867975
  Computing residual vector... norm=0.212073
  Solving linear system
  Computing residual vector... norm=0.212073
  Computing residual vector... norm=0.202631
  Solving linear system
  Computing residual vector... norm=0.202631
  Computing residual vector... norm=0.165773
  Solving linear system
  Computing residual vector... norm=0.165774
  Computing residual vector... norm=0.162594
  Solving linear system
  Computing residual vector... norm=0.162594
  Computing residual vector... norm=0.148175
  Solving linear system
  Computing residual vector... norm=0.148175
  Computing residual vector... norm=0.145391
  Solving linear system
  Computing residual vector... norm=0.145391
  Computing residual vector... norm=0.137551
  Solving linear system
  Computing residual vector... norm=0.137551
  Computing residual vector... norm=0.135366
  Solving linear system
  Computing residual vector... norm=0.135365
  Computing residual vector... norm=0.130367
  Solving linear system
  Computing residual vector... norm=0.130367
  Computing residual vector... norm=0.128704
  Computing Jacobian matrix
  Factorizing Jacobian matrix
  Solving linear system
  Computing residual vector... norm=0.128704
  Computing residual vector... norm=0.0302623
  Solving linear system
  Computing residual vector... norm=0.0302624
  Computing residual vector... norm=0.0126764
  Solving linear system
  Computing residual vector... norm=0.0126763
  Computing residual vector... norm=0.00488315
  Solving linear system
  Computing residual vector... norm=0.00488322
  Computing residual vector... norm=0.00195788
  Solving linear system
  Computing residual vector... norm=0.00195781
  Computing residual vector... norm=0.000773169


+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |     0.121s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| assembling the Jacobian         |         2 |    0.0151s |        12% |
| assembling the residual         |        31 |    0.0945s |        78% |
| factorizing the Jacobian        |         2 |   0.00176s |       1.5% |
| graphical output                |         1 |   0.00504s |       4.2% |
| linear system solve             |        15 |  0.000893s |      0.74% |
+---------------------------------+-----------+------------+------------+


Mesh refinement step 1
  Target_tolerance: 0.0001

  Computing residual vector... norm=0.2467
  Computing Jacobian matrix
  Factorizing Jacobian matrix
  Solving linear system
  Computing residual vector... norm=0.246699
  Computing residual vector... norm=0.0357783
  Solving linear system
  Computing residual vector... norm=0.0357784
  Computing residual vector... norm=0.0222161
  Solving linear system
  Computing residual vector... norm=0.022216
  Computing residual vector... norm=0.0122148
  Solving linear system
  Computing residual vector... norm=0.0122149
  Computing residual vector... norm=0.00750795
  Solving linear system
  Computing residual vector... norm=0.00750787
  Computing residual vector... norm=0.00439629
  Solving linear system
  Computing residual vector... norm=0.00439638
  Computing residual vector... norm=0.00265093
  Solving linear system

[...]
@endcode

The way this should be interpreted is most easily explained by looking at
the first few lines of the output on the first mesh:
@code
Mesh refinement step 0
Mesh refinement step 0
  Target_tolerance: 0.001

  Computing residual vector... norm=0.867975
  Computing Jacobian matrix
  Factorizing Jacobian matrix
  Solving linear system
  Computing residual vector... norm=0.867975
  Computing residual vector... norm=0.212073
  Solving linear system
  Computing residual vector... norm=0.212073
  Computing residual vector... norm=0.202631
  Solving linear system
  Computing residual vector... norm=0.202631
  Computing residual vector... norm=0.165773
  Solving linear system
  Computing residual vector... norm=0.165774
  Computing residual vector... norm=0.162594
  Solving linear system
  Computing residual vector... norm=0.162594
  Computing residual vector... norm=0.148175
  Solving linear system
  ...
@endcode
What is happening is this:
- In the first residual computation, KINSOL computes the residual to see whether
  the desired tolerance has been reached. The answer is no, so it requests the
  user program to compute the Jacobian matrix (and the function then also
  factorizes the matrix via SparseDirectUMFPACK).
- KINSOL then instructs us to solve a linear system of the form
  $J_k \, \delta U_k = -F_k$ with this matrix and the previously computed
  residual vector.
- It is then time to determine how far we want to go in this direction,
  i.e., do line search. To this end, KINSOL requires us to compute the
  residual vector $F(U_k + \alpha_k \delta U_k)$ for different step lengths
  $\alpha_k$. For the first step above, it finds an acceptable $\alpha_k$
  after two tries, and that's generally what will happen in later line
  searches as well.
- Having found a suitable updated solution $U_{k+1}$, the process is
  repeated except now KINSOL is happy with the current Jacobian matrix
  and does not instruct us to re-build the matrix and its factorization,
  instead asking us to solve a linear system with that same matrix. That
  will happen several times over, and only after ten solves with the same
  matrix are we instructed to build a matrix again, using what is by then an
  already substantially improved solution as linearization point.

The program also writes the solution to a VTU file at the end
of each mesh refinement cycle, and it looks as follows:
<table width="60%" align="center">
  <tr>
    <td align="center">
      <img src="https://www.dealii.org/images/steps/developer/step-77.solution.png" alt="">
    </td>
  </tr>
</table>


The key takeaway messages of this program are the following:

- The solution is the same as the one we computed in step-15, i.e., the
  interfaces to %SUNDIALS' KINSOL package really did what they were supposed
  to do. This should not come as a surprise, but the important point is that
  we don't have to spend the time implementing the complex algorithms that
  underlie advanced nonlinear solvers ourselves.

- KINSOL is able to avoid all sorts of operations such as rebuilding the
  Jacobian matrix when that is not actually necessary. Comparing the
  number of linear solves in the output above with the number of times
  we rebuild the Jacobian and compute its factorization should make it
  clear that this leads to very substantial savings in terms of compute
  times, without us having to implement the intricacies of algorithms
  that determine when we need to rebuild this information.


<a name="extensions"></a>
<h3> Possibilities for extensions </h3>

For all but the small problems we consider here, a sparse direct solver
requires too much time and memory -- we need an iterative solver like
we use in many other programs. The trade-off between constructing an
expensive preconditioner (say, a geometric or algebraic multigrid method)
is different in the current case, however: Since we can re-use the same
matrix for numerous linear solves, we can do the same for the preconditioner
and putting more work into building a good preconditioner can more easily
be justified than if we used it only for a single linear solve as one
does for many other situations.

But iterative solvers also afford other opportunities. For example (and as
discussed briefly in the introduction), we may not need to solve to
very high accuracy (small tolerances) in early nonlinear iterations as long
as we are still far away from the actual solution. This was the basis of the
Eisenstat-Walker trick mentioned there. (This is also the underlying reason
why one can store the matrix in single precision rather than double precision,
see the discussion in the "Possibilities for extensions" section of step-15.)

KINSOL provides the function that does the linear solution with a target
tolerance that needs to be reached. We ignore it in the program above
because the direct solver we use does not need a tolerance and instead
solves the linear system exactly (up to round-off, of course), but iterative
solvers could make use of this kind of information -- and, in fact, should.
